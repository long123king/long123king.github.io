<html xmlns="http://www.w3.org/1999/xhtml" lang="zh-cn">
<head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"></head>
<title>&#x5173;&#x4E8E;compiler&#x548C;linker&#x7684;&#x591A;&#x4E2A;&#x95EE;&#x9898;</title>
<body><p>即使不研究细节，也要了解其大致过程。</p> <h4>1. 对于符号的处理过程，程序中的编写的各种符号的声明和定义，是如何被compiler处理的</h4> <p>符号包含：</p> <p><strong><font color="#000000">1.1. 变量</font></strong></p> <p><strong><font color="#000000">1.2. 函数</font></strong></p> <p><strong><font color="#000000">1.3. 类</font></strong></p> <p>&nbsp;</p> <p>declarision</p> <p>implemetation</p> <p>分别会被compiler怎样处理</p> <p>&nbsp;</p> <p>这些符号，最终有哪些部分会直接转化成disassemble代码，而哪些是起到了控制转化的目的，而没有出现在最终的disassemble代码中。</p> <p>&nbsp;</p> <h4>2. 目标文件与可执行文件中都包含哪些内容</h4> <p>一般来说，目标文件只是一个.cpp源码文件的体现，它只是整个程序的一部分。</p> <p>首先，它会包含header文件中的各种符号的声明，比如类声明，全局或者静态变量的声明。</p> <p>然后，它会拥有一个包含了预处理过程结果的中间文件，这个文件的语法仍然是C++语法，只不过这个文件是一个自包含的，独立的单位。</p> <p>它里面可以有自己内部的一些实现，比如自己的header文件中声明的类的实现；</p> <p>它里面也可以有一些对于外部符号的依赖或者说是调用，这些符号是需要在link阶段解析(resolve)的。</p> <p>&nbsp;</p> <p>先说它内部对于符号的实现，比如一个类及其成员变量和函数，可以参考C++对象模型，它的类对象，其实是一个类似结构体一样，里面包含数据成员，最终在disasm中，肯定是以内存块的形式保存，由各个引用它的disasm代码块按其定义的布局解析它而已。</p> <p>因此类及其数据结构，最终是不会体现到disasm代码中的。</p> <p>&nbsp;</p> <p>至于虚函数表，它是存在于类对象的头部的，会动态地将真实函数的地址写入vtable中，因此虚函数构成了间接调用的目标中的一部分。</p> <p>&nbsp;</p> <p>其次是类的成员函数，它肯定在disasm中是对应一片或者多片代码块的。</p> <p>&nbsp;</p> <p>而全局的函数与成员函数是一样的，只是成员函数的第一个参数一定指向一个类对象而已。</p> <p>&nbsp;</p> <p>对于已经初始化的全局变量，它们会保存在PE文件中，将来在加载时加载到相应的内存区域。</p> <p>&nbsp;</p> <p>对于未初始化的全局变量，它们会在PE文件中保存记录，但是不占空间，将来也会映射到内存区域中。</p> <p>&nbsp;</p> <p>对于动态的缓存区域，比如堆和栈，都不会体现在PE中，是在程序运行时，由运行库和操作系统负责分配和维护的。</p> <p>&nbsp;</p> <p> <hr> 总线一下，数据结构是不会出现在disasm中，取而代之的是访问其的逻辑代码，会被嵌入到访问该数据结构的代码块中。  <p>而这些代码块就是类的成员函数以及全局函数。</p> <p>&nbsp;</p> <p>对于类的实例，即对象，如果是在程序中静态地初始化的，会保存在文件中，最终映射到内存区域中，说到底只是一片内存区域中的数据而已，并没有标记数据的类型。</p> <p>&nbsp;</p> <p> <hr> 说到逆向，最关心的源代码的逻辑，但是由于存在<strong>What You See Is Not What You eXecute</strong>现象，（主要是由于编译器的优化导致），因此逆向其实更应该关心的是经过Binary反推回来的中间代码，它最能代表Binary的真实逻辑。  <p>&nbsp;</p> <blockquote> <p>we are interested in recovering IRs that represent the following information:<br><strong>1. control-flow graphs (CFGs), with indirect jumps resolved<br>2. a call graph, with indirect calls resolved<br>3. information about the program’s variables<br>4. possible values of pointer variables<br>5. sets of used, killed, and possibly-killed variables for each CFG node<br>6. data dependences (including dependences between instructions that involve memory accesses)<br>7. type information (e.g., base types, pointer types, and structs)</strong></p> <p><br>Once such IRs are in hand, we will be in a position to leverage the substantial body of work on source-code-vulnerability analysis.</p> <p><a title="http://research.cs.wisc.edu/wpis/papers/pepm06.invited.pdf" href="http://research.cs.wisc.edu/wpis/papers/pepm06.invited.pdf">http://research.cs.wisc.edu/wpis/papers/pepm06.invited.pdf</a></p></blockquote> <blockquote> <p>However, in executables, memory is accessed either directly—by specifying an absolute address—<br>or indirectly—through an address expression of the form </p> <p><strong>“[<font color="#ff0000">base</font> + <font color="#ff0000">index</font> * <font color="#0000ff">scale</font> + <font color="#0000ff">offset</font>]”, </strong></p> <p>where base and index are <strong><font color="#ff0000">registers</font></strong> and</p> <p>scale and offset are integer <strong><font color="#0000ff">constants</font></strong>.</p></blockquote> <blockquote> <p>a crucial step in IR recovery is to identify <strong>variable-like entities</strong>.</p> <p>&nbsp;</p></blockquote> <blockquote> <p>A little endian architecture puts the low-order byte first, and a big-endian architecture<br>puts the high-order byte first. </p></blockquote></body>
</html>
